# 数据密集型应用系统设计

近几年各种概念商业名称层出不穷，无论是NoSQL ,BigData,WebScale,Sharding,Enventual consistency,ACID,CAP,云服务，MapReduce还是Real-time等等，其实都是围绕着高效存储和数据处理这一核心主题来阐述的，包括最近的Server-Mesh等等，由于目前CPU目前增长已经达到了一个高峰，所以对于并行分布式系统自然成为主流。对于分布式系统，**消息队列，缓存，搜索引擎，批处理和流处理框架**技术都非常重要，例如在最近字节跳动的招聘上面，对于Java后端这些技术都是最基本的技术。

关于DDIA这本书，目前做了个小整理，以及补充，本书共分三大部分：

第一部分1-4章，第二部分5-9章，第三部分10-12章

* 主要讨论增强数据密集型系统所需的原则，第一章讲述**可靠性，可扩展性，可维护性**，第二章比较不同数据模型以及查询语言，讨论使用场景，第三章针对存储引擎，数据库如何安排磁盘结构从而提高检索效率，第四章转向数据编码（序列化）方面，包括常见模式的演进。
* 从单机的数据存储转到跨机器的分布式系统，这是扩展性的第一步，但是随之而来的是各种挑战，依次讨论了数据远程复制（5）数据分区（6）以及事务（7），第八章讨论分布式系统的更多细节，以及分布式环境如何达成一致性与共识（9）
* 针对派生数据系统，派生数据是在异构系统中，如果无法通过一个数据源来解决所有问题，那么一个比较合理的做法就是集成多个不同的数据库，索引模块，缓存模块，第十章批处理来处理派生数据，十一章采用流处理，十二章总结之前介绍的多种技术，并分析未来构建可靠，可扩展和可维护的应用系统的新方向或方法

## 第一章：可靠可扩展和可维护的应用系统

本章注重介绍术语以及方法，重点是介绍可靠性可维护性以及可扩展的设计目标

* 可靠性：**容忍硬件，软件失效，人为错误**

主要描述当意外发生时候，系统应该可以正常运转，虽然性能有所降低，但是确保功能正常

* 可扩展性：**均测负载与性能，延迟百分数，吞吐量**

随着规模增加，例如数据量，流量或者复杂性增加，系统应该以合理的方式来匹配这种增长

* 可维护性：**可运维，简单，可演化**

随着时间的推移，许多人员会参与到系统开发和运维中去，以维护现有功能或适配新场景，系统都应该高效运转

下面对本章重点做个列举

### 可靠性

可靠性是指意外发生，这里意外有很多，可能人为失误，软件，硬件都可能，理清两个概念故障和失效

* 故障通常被定义为组建偏离正常规格（故障概率是很大的不可能不故障）
* 失效意味着系统作为一个整体停止无法提供服务

所以我们设计的容错机制避免故障引发系统失效

```markdown
很多系统都有单元测试，防止开发过程中出现软件问题，也降低发生风险，还有一种提供测试目的的方法，故意提高故障发生概率，来持续检验，测试系统的容错机制，也就是混沌工程
混沌工程是发现新信息的实验过程，而故障注入则是对特定条件变量的检验方法
一半混沌工程例如
* 模拟整个服务区或者数据中心的故障
* 跨多个实例删除部分Kafka Topic，重现生产环境问题
* 挑选一个时间段，针对部分流量服务注入延迟
* 方法级别混沌，让方法随机抛异常
* 强制系统节点时间不同步
* 驱动程序中执行模拟I/O错误程序
* 让ES集群CPU超负荷运行
```

一般的弹性故障都采用自动化冗余回滚解决

### 可扩展性

可扩展性是描述系统应对负载增加能力的术语，但这不是一维指标，谈论某个系统可扩展和不扩展无意义，主要是要了解这个问题

* 如果系统以某种方式增长，我们应对增长的措施有哪些
* 我们该如何添加计算资源来处理额外的负载

**描述负载**

描述负载才能解决后续增长方案，负载可以用负载参数的若干数字来描述，取决于系统体系结构，可能是Web服务器每秒请求的次数，数据库写入的比例，聊天室同时活动用户数量，缓存命中率。有时候平均值有时候峰值，取决于实际系统的瓶颈问题

**Twitter案例**

两个典型业务

* 发布Tweeter消息，用户可以快速推送新消息到所有关注者，平均4.6K request/sec，峰值为12k requests/sec
* 主页时间线，平均200K requests/sec查看关注对象最新消息

Tweeter两个方案以及瓶颈（最后是结合起来用的，我感觉微博其实也差不了太多）

* 将发送新的推插入到全局集合里面，用户查看时间线时候，首先查找所以关注对象，列出所有人的推，最后时间为序排序合并

缺点：主页时间线负载压力很大，如果采用第二种方式，发布的时候就已经做了缓存，负载大大缩小

* 对每个用户维护一个缓存，用户推送推时候，推送到每个关注着时间线缓存中，访问很快

缺点：对于某些用户，关注着超过几千万人，如果快速写入缓存，又成为系统瓶颈

所以Twitter是根据用户关注者的分布情况（还阔以结合用户使用Twiter频率加权）来衡量负载参数，目前方案就是大多数用户的Tweet发布继续使用方案2，以一对多写入时间线，但是少数名人超多关注者采用类似方案一，推文被单独提取时和用户时间线合并

（这个其实微博有点类似，比如一个热点出来，名人的微博看不到反而。。。）

**描述性能**

例如在Hadoop批处理系统中，我们通常关心吞吐量，每秒可处理的记录条数，在线系统更看重服务响应时间

* 响应时间是客户端看到的：除了处理请求时间（服务时间，service time）外还有网络延迟和各种排队延迟
* 延迟则是处理请求花费在处理上的时间

最好不要将响应时间定义为一个数字，而是一个可度量的数值分布，即使请求一样多，但是由于其他因素而引入的一些随机抖动，这些因素可能包括上下文切换，进程调度，网络数据包丢失和TCP重传，GC，缺页中断和磁盘I/O等等，最好使用百分位数来衡量，例如中位数也称为p50，证明一般请求都大于这个数值，很显然，一个请求大于中位数的概率远远大于50%；

为了弄清楚异常值多糟糕，一般关注更大的百分位数，例如常见的p95,p99,采用较高响应时间的百分位数直接影响用户总体服务体验。

百分位数常用描述定义服务质量目标(SLO)和服务质量协议(SLA)，这是规定服务预期质量和可用性的合同

**实践中的百分位数**

例如我们的APM中，经常使用百分位数来更总系统指标，例如设置一个滑动窗口，监控其中的响应时间，滚动计算窗口中位数和各种百分位数，然后绘制性能图标，最简单就是排序，每分钟做排序，当然如果这种方式效率低，可以采用近似算法（**正向衰减，t-digest或HdrHistogram**）来计算百分数，CPU和内存开销都很低。

可扩展架构都是从通用模块构建而来背后往往有规律可行，所以一个是要对通用模块理解加深，知道怎么对比，一个是要多了解多种技术的组合，不要局限于一个技术。

### 可运维

**可运维性**

良好的可操作方便运营团队好管理，在设计上最好遵循以下

* 提供对系统运行时行为和内部的可观测，方便监控。--APM
* 支持自动化，与标准工具集成。 --CI/CD
* 避免绑定特定机器，在运行时候可以停机维护   --K8S
* 提供良好的文档和易于理的操作模式
* 提供良好的默认配置，允许管理员在需要时方便修改默认配置。 --Apollo
* 尝试自我修复，需要时让管理员手动挡
* 行为可预测，减少意外发生。--ChaosBlade

**简单性**

当系统庞大起来，其复杂性就立即提升了，拖慢了开发效率，增加了维护成本，例如状态空间的膨胀，模块紧耦合，相互依赖关系，不一致命名术语，为了性能采用的特殊处理，为了特殊问题而引入的特殊框架，最好消除复杂性手段就是抽象，一个好的抽象可以隐藏大量实现细节，对外提供干净易懂的接口

**可演化性**

一成不变的系统肯定不可能，例如为了适配新的外部环境，新的用例，业务优先级的变化，用户需求的新功能，新平台取代旧平台，法律监管要求或者业务增长要求等等。

组织流程上，敏捷开发模式(DevOps)很好可以参考，例如测试驱动开发(TDD) 业务驱动开发(DDD)或者重构等等

## 第二章：数据模型和查询语言

复杂的应用程序可能会有很多层，例如基于API来构建上层API，每层都通过提供一个简洁的数据模型来隐藏下层的复杂性，这也是一种抽象机制。本章主要讲解关系模型，文档模型和一些基于图的数据模型。

### 关系模型和文档模型

现在最著名的数据模型可能是SQL，数据被组织成关系，在SQL中成为表，每个关系都是元组(tuples)的无序集合(在SQL被称为行)

NoSQL数据库几个驱动因素

* 比关系数据库跟好扩展，支持超大数据集或超高写入吞吐量
* 基本都是免费开源
* 关系模型不能很好支持一些特定查询操作
* 对关系模型一些限制，需要动态和有表达力的数据模型

**对象关系不匹配**

现在大多数都是面向对象开发，由于兼容问题，如果数据存储在关系表中，应用层代码的对象和表，行，列的数据模型之间需要一个转换层(ORM)

但是比如简历，这种树状结构，采用文档数据JSON就很方便，如果关系数据就显得设计很繁杂了。但是JSON其实也存在问题。

### 关系数据库和文档数据库现状

比较关系数据库和文档数据库的差异需要考虑他们容错性（5）和并发处理（7），这里只考虑数据模型差异

对于文档数据库主要是模式灵活，由于局部性带来较好的性能，对于某些地方来说，更加接近应用程序所使用的结构，关系模型主要强在联结操作，多对多和一对多关系更加简洁的表达上。

**选择**

如果应用程序具有类似文档结构（即一对多关系树，通常一次加载整个树），那么使用文档模型更为合适，而关系数据库倾向于某种数据分解，他把文档结构分成多个表，有可能使结构变得更加复杂让代码更加复杂，但是文档也有一定局限，例如不能直接引用文档中的嵌套项，当嵌套多了就成问题了，例如我想拿出用户简历中实习经验的第二项（就类似层次中的访问）。

这其实也是需要根据用户系统去选择数据库，不能说哪个好哪个差，主要取决数据项的关系类型，对于高度联结的数据，文档数据库不适合，关系模型可以胜任，而图数据库确实最适合的。

**文档数据库的模式灵活性**

文档数据库有时候被称为无模式，这种有点不准确，应该说是某种隐形模式，应该说成读时模式（数据结构是隐式的，只有读取才解释），与写时模式（关系数据库的一种传统方法，模式是显式的，只有数据库确保数据写入都必须遵循），读时模式有点像编程语言的动态（运行时）类型检查，而写时模式有点类似静态（编译时）类型检查，这两个都有争议，不能说哪个好哪个坏。数据库模式执行也有争议。

**文档数据库和关系数据库的融合**

融合关系模型和文档模型是未来数据库发展一条很好途径，例如大多数关系数据库都对Json提供了支持，而比如文档数据库MongoDB也提供了自动解析数据库的引用关系，这两者正在互相接近，如果数据库能很好处理文档类数据，还能对其执行关系查询，那么应用程序可以使用最符合其功能的组合。

### 数据查询语言

关系模型时最初引入时候，包含了查询数据的新方法，SQL是一种声明式查询语言，而IMS和CODASYL是一种命令式的查询。命令式查询告诉计算机以特定顺序执行某些操作，而声明式查询语言只需要指定所需数据模式，结果满足什么条件，以及如何转化数据（排序，分组，聚合等）而不需要指明如何执行，数据库系统查询优化器会决定采用那种索引和联结以及何种顺序来执行。SQL不保证任何特定顺序，所以顺序改变不重要，如果命令编写，那么无法确定代码是否依赖于排序，SQL在功能上有更多限制，但是也给数据库提供了更多自动化空间。再者，声明式语言通常适合并行执行，现在CPU主要通过增加核而不是通过比之前更高的时钟频率来提升速度，命令代码由于制定了特定执行顺序，很难在多核和多台机器并行化，声明式仅指定了结果满足的模式，而不指定得到结果的具体算法，数据库都倾向于并行方式实现查询语言。

```js
// 对于是否依赖排序这里增加理解补充
//如果是命令式查询，就可能得写成这样了
// 这种类似方法会导致指定了查询算法而且依赖于输出顺序，在底层如果进行回收磁盘时候，很难保证输出的稳定性
function getPerson(){
	for(int i=0;i<person.size;i++){
			if(person[i].name=="fourous"){
					person.push(person[i]);
			}
	}
}
// 声明式查询
// 这种方式是不依赖于查询顺序的，如果要排序，会输出再排序，都在底层做了，屏蔽了底层细节问题
Select * from person where person = "fourous"
```

   ### MapReduce查询

MapReduce是一种编程模型，用于在许多机器上批量处理海量数据，一些NoSQL存储系统支持有限的MapReduce方式在大量文档大量执行只读查询。

### 图状数据库

我们知道，多对多关系是不同的数据模型之间的重要区别，如果数据大多是一对多关系（树结构数据）或者记录之间没有关系，那么文档模型最合适。但是如果数据之间关系是多对多关系，随着关联复杂，将数据建模转换为图模型将更加自然。

文档数据库和图数据库有一个共同点，那就是他们通常不会对存储的数据强加某个模式，可以使应用程序更加容易适应不断变化的需求，但是，应用程序很可能仍然假定数据具有一定的结构，只不过模式是显式（写时处理）的还是隐式（读时处理）的问题

## 第三章：数据存储与检索

本章主要从数据库的角度探讨如何存储输入的数据，并在收到查询请求时候，怎么样重新找到数据，我们之所以关注数据库内部的存储和检索，主要是因为我们需要从众多的存储引擎选择一个适合自己应用的存储引擎，因此，为了针对特定的工作负载而对数据库调优时，最好对存储引擎的底层机制有个大概了解。

特别针对事务型工作负载和针对分析型负载的存储引擎优化存在很大的差异。

在存储引擎上，本章着重研究两个存储引擎家族，日志结构存储引擎和面向页的存储引擎结构

### 数据库核心：数据结构

书中实现了一个很简单很简单的日志存储数据库，一个纯文本文件，每行包含一个Key-Value对，用逗号分隔，每次调用函数追加新内容到文件末尾，因此，**如果多次更新某个键，旧版本的值不会被覆盖，而是需要查看文件中最后一次出现的键找到最新值**

> 很多数据库内部都使用日志（log），日志是一个仅支持追加式更新的数据文件，虽然真正的数据库有很多更加复杂的问题需要考虑（例如并发控制，回收磁盘空间，以及控制日志文件大小，处理错误，和部分完成写记录等），但是基本原理相同，日志机制很有用！当然这里如果进行搜索，又是一件难事，因为全盘扫描肯定复杂度是O(n)了

**索引**

为了高效查询数据库特定的键值，需要新的数据结构，索引，基本原理都是保留一些额外的元数据，用这个做路标定位到数据，虽然索引能增快查询速度，但是因为每次写的时候，都要跟新索引，所以索引不能胡乱加。

### 哈希索引

